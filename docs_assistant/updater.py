import os
import json
import time
import hashlib
import requests
import logging
from datetime import datetime
import yaml
import re
import threading

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('docs-updater')

# ç¯å¢ƒå˜é‡é…ç½®
UPDATE_INTERVAL = int(os.environ.get('UPDATE_INTERVAL', 1800))  # é»˜è®¤30åˆ†é’Ÿ
GITHUB_REPO = os.environ.get('GITHUB_REPO', 'Calcium-Ion/new-api')
GITHUB_PROXY = os.environ.get('GITHUB_PROXY', 'https://api2.aimage.cc/proxy')
USE_PROXY = os.environ.get('USE_PROXY', 'true').lower() == 'true'
DOCS_DIR = os.environ.get('DOCS_DIR', '/app/docs')

# å…¨å±€çŠ¶æ€
class AppState:
    def __init__(self):
        self.api_failures = 0  # APIå¤±è´¥è®¡æ•°
        self.api_cooldown_until = 0  # APIå†·å´æ—¶é—´
        self.rebuild_cooldown = 0  # é‡å»ºå†·å´æ—¶é—´
        self.rebuild_triggered = False  # æ ‡è®°æ˜¯å¦å·²è§¦å‘é‡å»º
        
app_state = AppState()

def fetch_github_data(repo, data_type, count, use_proxy=True):
    """è·å–GitHubæ•°æ®"""
    logger.info(f"è·å–GitHubæ•°æ®: {repo}, {data_type}, count={count}")
    
    headers = {'User-Agent': 'Mozilla/5.0 DocUpdater/1.0'}
    
    try:
        # æ£€æŸ¥APIå†·å´æ—¶é—´
        current_time = time.time()
        if current_time < app_state.api_cooldown_until:
            cooldown_remaining = int(app_state.api_cooldown_until - current_time)
            logger.info(f"GitHub APIå†·å´ä¸­ï¼Œè·³è¿‡è¯·æ±‚ (å‰©ä½™ {cooldown_remaining} ç§’)")
            return None, False
            
        # æ„å»ºAPIè·¯å¾„
        if data_type == "releases":
            api_path = f'repos/{repo}/releases?per_page={count}'
        elif data_type == "contributors":
            api_path = f'repos/{repo}/contributors?per_page={count}'
        else:
            return None, False
        
        # æ„å»ºAPI URL
        if use_proxy and USE_PROXY:
            original_api_url = f'https://api.github.com/{api_path}'
            api_url = f'{GITHUB_PROXY}?url={original_api_url}'
        else:
            api_url = f'https://api.github.com/{api_path}'
        
        # å‘é€è¯·æ±‚
        response = requests.get(api_url, headers=headers, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        # æˆåŠŸè·å–æ•°æ®ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
        app_state.api_failures = 0
        
        # å¤„ç†åˆ†é¡µ (å¦‚æœéœ€è¦)
        if data_type == "contributors" and len(data) < count and len(data) > 0:
            all_data = data.copy()
            page = 2
            
            # æœ€å¤šè·å–5é¡µ
            while len(all_data) < count and page <= 5:
                # æ„å»ºä¸‹ä¸€é¡µURL
                next_api_url = f'{api_path}&page={page}'
                if use_proxy and USE_PROXY:
                    next_url = f'{GITHUB_PROXY}?url=https://api.github.com/{next_api_url}'
                else:
                    next_url = f'https://api.github.com/{next_api_url}'
                
                next_response = requests.get(next_url, headers=headers, timeout=30)
                next_response.raise_for_status()
                next_data = next_response.json()
                
                if not next_data:
                    break
                    
                all_data.extend(next_data)
                page += 1
                time.sleep(1)  # é¿å…è§¦å‘é™åˆ¶
            
            return all_data[:count], True
        
        return data, True
    
    except requests.exceptions.RequestException as e:
        logger.error(f"APIè¯·æ±‚å¤±è´¥: {str(e)}")
        
        # å¤„ç†é™é€Ÿé”™è¯¯
        if hasattr(e, 'response') and e.response and e.response.status_code == 403 and "rate limit exceeded" in str(e.response.text).lower():
            app_state.api_failures += 1
            cooldown_time = 60 * (2 ** min(app_state.api_failures, 6))  # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤š64åˆ†é’Ÿ
            app_state.api_cooldown_until = time.time() + cooldown_time
            logger.warning(f"GitHub APIé™é€Ÿï¼Œè®¾ç½®å†·å´æ—¶é—´ {cooldown_time} ç§’")
        
        # å¦‚æœä»£ç†å¤±è´¥ï¼Œå°è¯•ç›´æ¥è®¿é—®
        if use_proxy and USE_PROXY:
            logger.info("ä»£ç†è¯·æ±‚å¤±è´¥ï¼Œå°è¯•ç›´æ¥è®¿é—®")
            return fetch_github_data(repo, data_type, count, False)
        
        return None, False
    except Exception as e:
        logger.error(f"è·å–æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        
        # å¢åŠ å¤±è´¥è®¡æ•°å’Œå†·å´æ—¶é—´
        app_state.api_failures += 1
        cooldown_time = 30 * app_state.api_failures  # çº¿æ€§å¢åŠ å†·å´æ—¶é—´
        app_state.api_cooldown_until = time.time() + cooldown_time
        logger.warning(f"è®¾ç½®APIå†·å´æ—¶é—´ {cooldown_time} ç§’")
        
        return None, False

def update_mkdocs_timestamp():
    """æ›´æ–°MkDocsé…ç½®æ–‡ä»¶æ—¶é—´æˆ³ï¼Œè§¦å‘é‡å»º"""
    current_time = time.time()
    if current_time < app_state.rebuild_cooldown:
        logger.info(f"é‡å»ºå†·å´ä¸­ï¼Œè·³è¿‡è§¦å‘ (å‰©ä½™ {int(app_state.rebuild_cooldown - current_time)} ç§’)")
        return False
        
    if app_state.rebuild_triggered:
        logger.info("å·²ç»è§¦å‘è¿‡é‡å»ºï¼Œè·³è¿‡")
        return False
        
    try:
        # æŸ¥æ‰¾MkDocsé…ç½®æ–‡ä»¶
        config_file = os.path.join(DOCS_DIR, 'mkdocs.yml')
        if os.path.exists(config_file):
            # è®¾ç½®é‡å»ºæ ‡è®°å’Œå†·å´æ—¶é—´
            app_state.rebuild_triggered = True
            app_state.rebuild_cooldown = current_time + 60  # 60ç§’å†·å´æ—¶é—´
            
            # æ›´æ–°æ—¶é—´æˆ³
            os.utime(config_file, None)
            logger.info(f"å·²æ›´æ–°é…ç½®æ–‡ä»¶ {config_file} çš„æ—¶é—´æˆ³")
            
            # 5ç§’åé‡ç½®è§¦å‘æ ‡è®°
            def reset_trigger():
                time.sleep(5)
                app_state.rebuild_triggered = False
                
            threading.Thread(target=reset_trigger, daemon=True).start()
            return True
        else:
            logger.error(f"æœªæ‰¾åˆ°MkDocsé…ç½®æ–‡ä»¶: {config_file}")
            return False
    except Exception as e:
        logger.error(f"æ›´æ–°æ—¶é—´æˆ³å¤±è´¥: {str(e)}")
        return False

def format_date(date_string):
    """æ ¼å¼åŒ–æ—¥æœŸ"""
    if not date_string:
        return ""
    try:
        date_obj = datetime.strptime(date_string, "%Y-%m-%dT%H:%M:%SZ")
        return date_obj.strftime("%Y-%m-%d %H:%M:%S")
    except Exception:
        return date_string

def format_file_size(bytes):
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    if bytes < 1024:
        return f"{bytes} B"
    elif bytes < 1024 * 1024:
        return f"{bytes/1024:.2f} KB"
    elif bytes < 1024 * 1024 * 1024:
        return f"{bytes/(1024*1024):.2f} MB"
    else:
        return f"{bytes/(1024*1024*1024):.2f} GB"

def format_contributors_markdown(contributors_data):
    """å°†è´¡çŒ®è€…æ•°æ®æ ¼å¼åŒ–ä¸ºMarkdownå†…å®¹ - ä½¿ç”¨åŸå§‹é£æ ¼"""
    if not contributors_data or len(contributors_data) == 0:
        return "æš‚æ— è´¡çŒ®è€…æ•°æ®ï¼Œè¯·ç¨åå†è¯•ã€‚"
    
    # æ·»åŠ ç¼“å­˜çŠ¶æ€ä¿¡æ¯
    markdown_content = f'''!!! note "æ•°æ®ä¿¡æ¯"
    æ•°æ®æ›´æ–°äº: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} (æ¯30åˆ†é’Ÿè‡ªåŠ¨æ£€æŸ¥æ›´æ–°)

'''
    
    # ä¸ºæ¯ä¸ªè´¡çŒ®è€…åˆ›å»ºæ¡ç›®
    for index, contributor in enumerate(contributors_data):
        username = contributor.get('login', 'æœªçŸ¥ç”¨æˆ·')
        avatar_url = contributor.get('avatar_url', '')
        profile_url = contributor.get('html_url', '#')
        contributions = contributor.get('contributions', 0)
        
        # è·å–å‰ä¸‰åçš„ç‰¹æ®Šæ ·å¼
        medal_class = ""
        medal_label = ""
        if index == 0:
            medal_class = "gold-medal"
            medal_label = '<span class="medal-rank rank-1">1</span>'
        elif index == 1:
            medal_class = "silver-medal"
            medal_label = '<span class="medal-rank rank-2">2</span>'
        elif index == 2:
            medal_class = "bronze-medal"
            medal_label = '<span class="medal-rank rank-3">3</span>'
        
        # ä¸‰çº§æ ‡é¢˜ + ç®€è¦ä»‹ç»
        markdown_content += f'### {username}\n\n'
        markdown_content += f'<div class="contributor-simple {medal_class}">\n'
        markdown_content += f'  <div class="avatar-container">\n'
        markdown_content += f'    <img src="{avatar_url}" alt="{username}" class="contributor-avatar" />\n'
        if medal_label:
            markdown_content += f'    {medal_label}\n'
        markdown_content += f'  </div>\n'
        markdown_content += f'  <div class="contributor-details">\n'
        markdown_content += f'    <a href="{profile_url}" target="_blank">{username}</a>\n'
        markdown_content += f'    <span class="contributor-stats">è´¡çŒ®æ¬¡æ•°: {contributions}</span>\n'
        markdown_content += f'  </div>\n'
        markdown_content += f'</div>\n\n'
        markdown_content += '---\n\n'
    
    # æ·»åŠ CSSæ ·å¼
    markdown_content += '''
<style>
.contributor-simple {
    display: flex;
    align-items: center;
    margin-bottom: 10px;
}

.avatar-container {
    position: relative;
    margin-right: 15px;
}

.contributor-avatar {
    width: 50px;
    height: 50px;
    border-radius: 50%;
}

.medal-rank {
    position: absolute;
    bottom: -5px;
    right: -5px;
    width: 22px;
    height: 22px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    font-weight: bold;
    font-size: 12px;
    color: white;
    box-shadow: 0 2px 4px rgba(0,0,0,0.2);
}

.rank-1 {
    background-color: #ffd700;
}

.rank-2 {
    background-color: #c0c0c0;
}

.rank-3 {
    background-color: #cd7f32;
}

.gold-medal .contributor-avatar {
    border: 4px solid #ffd700;
    box-shadow: 0 0 10px #ffd700;
}

.silver-medal .contributor-avatar {
    border: 4px solid #c0c0c0;
    box-shadow: 0 0 10px #c0c0c0;
}

.bronze-medal .contributor-avatar {
    border: 4px solid #cd7f32;
    box-shadow: 0 0 10px #cd7f32;
}

.contributor-details {
    display: flex;
    flex-direction: column;
}

.contributor-details a {
    font-weight: 500;
    text-decoration: none;
}

.contributor-stats {
    font-size: 0.9rem;
    color: #666;
}

[data-md-color-scheme="slate"] .contributor-stats {
    color: #aaa;
}
</style>
'''
    
    return markdown_content

def format_releases_markdown(releases_data):
    """å°†å‘å¸ƒæ•°æ®æ ¼å¼åŒ–ä¸ºMarkdownå†…å®¹ - ä½¿ç”¨åŸå§‹é£æ ¼"""
    if not releases_data or len(releases_data) == 0:
        return "æš‚æ— ç‰ˆæœ¬æ•°æ®ï¼Œè¯·ç¨åå†è¯•ã€‚"
    
    markdown_content = "# ğŸ“ æ›´æ–°æ—¥å¿—\n\n"
    
    # æ·»åŠ ç¼“å­˜çŠ¶æ€ä¿¡æ¯
    markdown_content += f'!!! note "æ•°æ®ä¿¡æ¯"\n'
    markdown_content += f'    æ•°æ®æ›´æ–°äº: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")} (æ¯30åˆ†é’Ÿè‡ªåŠ¨æ£€æŸ¥æ›´æ–°)\n\n'
    
    # éå†å‘å¸ƒç‰ˆæœ¬
    for index, release in enumerate(releases_data):
        # è·å–å‘å¸ƒä¿¡æ¯
        prerelease = release.get('prerelease', False)
        tag_name = release.get('tag_name', '')
        name = release.get('name') or tag_name
        created_at = format_date(release.get('created_at', ''))
        body = release.get('body', '')
        
        # å¤„ç†å†…å®¹ä¸­çš„å›¾ç‰‡é“¾æ¥
        if USE_PROXY:
            # æ›¿æ¢Markdownæ ¼å¼çš„å›¾ç‰‡é“¾æ¥
            def replace_md_img(match):
                alt_text = match.group(1)
                img_url = match.group(2)
                return f'![{alt_text}]({GITHUB_PROXY}?url={img_url})'
            
            body = re.sub(r'!\[(.*?)\]\((https?://[^)]+)\)', replace_md_img, body)
            
            # æ›¿æ¢HTMLæ ¼å¼çš„å›¾ç‰‡é“¾æ¥
            def replace_html_img(match):
                prefix = match.group(1)
                img_url = match.group(2)
                suffix = match.group(3)
                return f'<img{prefix}src="{GITHUB_PROXY}?url={img_url}"{suffix}>'
            
            body = re.sub(r'<img([^>]*)src="(https?://[^"]+)"([^>]*)>', replace_html_img, body)
        
        # å¤„ç†å†…å®¹ä¸­çš„æ ‡é¢˜ï¼Œç¡®ä¿æ‰€æœ‰æ ‡é¢˜è‡³å°‘æ˜¯ä¸‰çº§æ ‡é¢˜
        # é¦–å…ˆç§»é™¤åŸå§‹å†…å®¹ä¸­å¯èƒ½å­˜åœ¨çš„HTMLæ ‡ç­¾
        body = re.sub(r'<[^>]+>', '', body)
        
        # é¢„å¤„ç†ï¼šç»Ÿä¸€å¤„ç†Markdownæ ‡é¢˜æ ¼å¼
        # 1. ç§»é™¤æ¯è¡Œå¼€å¤´å’Œç»“å°¾çš„ç©ºç™½å­—ç¬¦
        body = re.sub(r'^\s+|\s+$', '', body, flags=re.MULTILINE)
        
        # 2. ç¡®ä¿æ ‡é¢˜å‰æœ‰ç©ºè¡Œï¼ˆæ›´å¥½çš„åˆ†éš”ï¼‰
        body = re.sub(r'([^\n])\n(#{1,6} )', r'\1\n\n\2', body)
        
        # 3. å¤„ç†æ ‡é¢˜ï¼šä¾æ¬¡å¤„ç†1çº§åˆ°6çº§æ ‡é¢˜
        for i in range(1, 7):
            heading = '#' * i
            
            # æ”¹è¿›çš„æ ‡é¢˜çº§åˆ«å¤„ç†:
            # - ä¸€çº§æ ‡é¢˜å˜ä¸ºä¸‰çº§æ ‡é¢˜
            # - å…¶ä»–æ ‡é¢˜åªæå‡ä¸€çº§ï¼Œä½†ç¡®ä¿ä¸è¶…è¿‡æœ€å¤§çº§åˆ«
            if i == 1:
                new_level = 3  # ä¸€çº§æ ‡é¢˜ç»Ÿä¸€å˜ä¸ºä¸‰çº§
            else:
                new_level = min(i + 1, 6)  # å…¶ä»–æ ‡é¢˜æå‡ä¸€çº§ï¼Œä½†ä¸è¶…è¿‡å…­çº§
                
            new_heading = '#' * new_level
            
            # æ›´å¼ºå¤§çš„æ ‡é¢˜åŒ¹é…æ¨¡å¼ï¼Œå¿½ç•¥è¡Œé¦–ç©ºç™½ï¼Œç¡®ä¿åŒ¹é…æ ‡é¢˜åçš„ç©ºæ ¼å’Œå†…å®¹
            pattern = r'(^|\n)[ \t]*' + re.escape(heading) + r'[ \t]+(.+?)[ \t]*(\n|$)'
            replacement = r'\1' + new_heading + r' \2\3'
            body = re.sub(pattern, replacement, body)
        
        # ç‰ˆæœ¬å·ä½œä¸ºäºŒçº§æ ‡é¢˜
        markdown_content += f'## {tag_name}\n\n'
        
        # æœ€æ–°ç‰ˆæœ¬ç›´æ¥æ˜¾ç¤º"æœ€æ–°ç‰ˆæœ¬"ï¼Œå…¶ä»–ç‰ˆæœ¬æ˜¾ç¤ºæ­£å¼/é¢„å‘å¸ƒç‰ˆæœ¬
        if index == 0:
            version_type = "æœ€æ–°ç‰ˆæœ¬"
        else:
            version_type = "é¢„å‘å¸ƒç‰ˆæœ¬" if prerelease else "æ­£å¼ç‰ˆæœ¬"
        
        # ä¸ºæœ€æ–°ç‰ˆæœ¬ä½¿ç”¨ä¸åŒé¢œè‰²çš„admonition
        admonition_type = "success" if index == 0 else "info"
        markdown_content += f'???+ {admonition_type} "{version_type} Â· å‘å¸ƒäº {created_at}"\n\n'
        
        # ç¼©è¿›å†…å®¹ä»¥é€‚åº”admonitionæ ¼å¼
        indented_body = '\n'.join(['    ' + line for line in body.split('\n')])
        markdown_content += f'{indented_body}\n\n'
        
        # æ·»åŠ èµ„æºä¸‹è½½éƒ¨åˆ†ï¼ˆä»åœ¨admonitionå†…éƒ¨ï¼Œä½†ä½œä¸ºæ™®é€šæ–‡æœ¬ï¼‰
        assets = release.get('assets', [])
        if assets or tag_name:
            markdown_content += '    **ä¸‹è½½èµ„æº**\n\n'
            # æ·»åŠ æ­£å¸¸èµ„æº
            for asset in assets:
                name = asset.get('name', '')
                url = asset.get('browser_download_url', '')
                # æ›¿æ¢ä¸‹è½½URLä¸ºä»£ç†URL
                if USE_PROXY and 'github.com' in url:
                    url = f'{GITHUB_PROXY}?url={url}'
                size = format_file_size(asset.get('size', 0))
                markdown_content += f'    - [{name}]({url}) ({size})\n'
            
            # åœ¨ä¸‹è½½èµ„æºéƒ¨åˆ†ç›´æ¥æ·»åŠ æºä»£ç ä¸‹è½½é“¾æ¥
            if tag_name:
                # æ„å»ºzipä¸‹è½½é“¾æ¥
                zip_url = f'https://github.com/{GITHUB_REPO}/archive/refs/tags/{tag_name}.zip'
                if USE_PROXY:
                    proxy_zip_url = f'{GITHUB_PROXY}?url={zip_url}'
                    markdown_content += f'    - [Source code (zip)]({proxy_zip_url})\n'
                else:
                    markdown_content += f'    - [Source code (zip)]({zip_url})\n'
                
                # æ„å»ºtar.gzä¸‹è½½é“¾æ¥
                tar_url = f'https://github.com/{GITHUB_REPO}/archive/refs/tags/{tag_name}.tar.gz'
                if USE_PROXY:
                    proxy_tar_url = f'{GITHUB_PROXY}?url={tar_url}'
                    markdown_content += f'    - [Source code (tar.gz)]({proxy_tar_url})\n'
                else:
                    markdown_content += f'    - [Source code (tar.gz)]({tar_url})\n'
            
            markdown_content += '\n'
        
        markdown_content += '---\n\n'
    
    return markdown_content

def update_markdown_file(file_path, content):
    """æ›´æ–°Markdownæ–‡ä»¶å†…å®¹"""
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        # å†™å…¥æ–‡ä»¶
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"å·²æ›´æ–°æ–‡ä»¶ {file_path}")
        return True
    except Exception as e:
        logger.error(f"æ›´æ–°Markdownæ–‡ä»¶å¤±è´¥: {str(e)}")
        return False

def update_special_thanks_file():
    """æ›´æ–°ç‰¹åˆ«æ„Ÿè°¢æ–‡ä»¶"""
    try:
        # è·å–è´¡çŒ®è€…æ•°æ®
        contributors_data, success = fetch_github_data(GITHUB_REPO, "contributors", 50)
        if not success or not contributors_data:
            logger.error("æ— æ³•è·å–è´¡çŒ®è€…æ•°æ®")
            return False
        
        # æ ¼å¼åŒ–ä¸ºMarkdown
        contributors_markdown = format_contributors_markdown(contributors_data)
        
        # è¯»å–åŸæ–‡ä»¶å†…å®¹
        thanks_file = os.path.join(DOCS_DIR, 'docs/wiki/special-thanks.md')
        if os.path.exists(thanks_file):
            with open(thanks_file, 'r', encoding='utf-8') as f:
                thanks_content = f.read()
            
            # æ‰¾åˆ°éœ€è¦æ›¿æ¢çš„éƒ¨åˆ†
            pattern = r'(!!! note "æ•°æ®ä¿¡æ¯".*?)(?=\n## |\Z)'
            if re.search(pattern, thanks_content, re.DOTALL):
                # å¦‚æœæ‰¾åˆ°äº†æ•°æ®ä¿¡æ¯éƒ¨åˆ†ï¼Œæ›¿æ¢æ•´ä¸ªéƒ¨åˆ†
                new_content = re.sub(pattern, contributors_markdown, thanks_content, flags=re.DOTALL)
                return update_markdown_file(thanks_file, new_content)
            else:
                # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå…ˆæŸ¥æ‰¾æ ‡é¢˜
                title_match = re.search(r'^# (.*?)$', thanks_content, re.MULTILINE)
                if title_match:
                    # ä¿ç•™æ ‡é¢˜ï¼Œæ·»åŠ æ–°å†…å®¹
                    title = title_match.group(0)
                    new_content = f"{title}\n\n{contributors_markdown}"
                    return update_markdown_file(thanks_file, new_content)
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°æ ‡é¢˜ï¼Œç›´æ¥æ·»åŠ å†…å®¹
                    full_content = f"# New API çš„å¼€å‘ç¦»ä¸å¼€ç¤¾åŒºçš„æ”¯æŒå’Œè´¡çŒ®ã€‚åœ¨æ­¤ç‰¹åˆ«æ„Ÿè°¢æ‰€æœ‰ä¸ºé¡¹ç›®æä¾›å¸®åŠ©çš„ä¸ªäººå’Œç»„ç»‡ã€‚\n\n{contributors_markdown}"
                    return update_markdown_file(thanks_file, full_content)
        else:
            # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºåŒ…å«å®Œæ•´å†…å®¹çš„æ–‡ä»¶
            full_content = f"# New API çš„å¼€å‘ç¦»ä¸å¼€ç¤¾åŒºçš„æ”¯æŒå’Œè´¡çŒ®ã€‚åœ¨æ­¤ç‰¹åˆ«æ„Ÿè°¢æ‰€æœ‰ä¸ºé¡¹ç›®æä¾›å¸®åŠ©çš„ä¸ªäººå’Œç»„ç»‡ã€‚\n\n{contributors_markdown}"
            return update_markdown_file(thanks_file, full_content)
    
    except Exception as e:
        logger.error(f"æ›´æ–°è´¡çŒ®è€…åˆ—è¡¨å¤±è´¥: {str(e)}")
        return False

def update_changelog_file():
    """æ›´æ–°æ›´æ–°æ—¥å¿—æ–‡ä»¶"""
    try:
        # è·å–å‘å¸ƒæ•°æ®
        releases_data, success = fetch_github_data(GITHUB_REPO, "releases", 30)
        if not success or not releases_data:
            logger.error("æ— æ³•è·å–å‘å¸ƒæ•°æ®")
            return False
        
        # æ ¼å¼åŒ–ä¸ºMarkdown
        releases_markdown = format_releases_markdown(releases_data)
        
        # æ›´æ–°åˆ°æ–‡ä»¶
        changelog_file = os.path.join(DOCS_DIR, 'docs/wiki/changelog.md')
        return update_markdown_file(changelog_file, releases_markdown)
    
    except Exception as e:
        logger.error(f"æ›´æ–°æ›´æ–°æ—¥å¿—å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¯åŠ¨æ–‡æ¡£æ›´æ–°æœåŠ¡")
    
    # æ£€æŸ¥MkDocsé…ç½®æ–‡ä»¶
    config_file = os.path.join(DOCS_DIR, 'mkdocs.yml')
    if os.path.exists(config_file):
        logger.info(f"æ‰¾åˆ°MkDocsé…ç½®æ–‡ä»¶: {config_file}")
    else:
        logger.warning(f"æœªæ‰¾åˆ°MkDocsé…ç½®æ–‡ä»¶: {config_file}")
    
    # è®¾ç½®åˆå§‹æ›´æ–°æ—¶é—´
    last_check = 0
    
    # ä¸»å¾ªç¯
    while True:
        try:
            current_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
            if current_time - last_check >= UPDATE_INTERVAL:
                logger.info("å¼€å§‹æ£€æŸ¥æ›´æ–°")
                last_check = current_time
                
                # æ›´æ–°æ–‡ä»¶
                changes_detected = False
                
                # æ›´æ–°è´¡çŒ®è€…åˆ—è¡¨
                if update_special_thanks_file():
                    changes_detected = True
                    logger.info("å·²æ›´æ–°è´¡çŒ®è€…åˆ—è¡¨")
                
                # ä¼‘çœ 5ç§’ï¼Œé¿å…è¿ç»­è¯·æ±‚
                time.sleep(5)
                
                # æ›´æ–°å‘å¸ƒæ—¥å¿—
                if update_changelog_file():
                    changes_detected = True
                    logger.info("å·²æ›´æ–°æ›´æ–°æ—¥å¿—")
                
                # å¦‚æœæœ‰å˜åŒ–ï¼Œè§¦å‘MkDocsé‡å»º
                if changes_detected:
                    logger.info("æ£€æµ‹åˆ°å˜åŒ–ï¼Œè§¦å‘MkDocsé‡å»º")
                    update_mkdocs_timestamp()
                else:
                    logger.info("æ²¡æœ‰æ£€æµ‹åˆ°å˜åŒ–ï¼Œè·³è¿‡è§¦å‘é‡å»º")
            
            # ä¼‘çœ ä¸€æ®µæ—¶é—´
            sleep_time = 60  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡æ˜¯å¦éœ€è¦æ›´æ–°
            logger.debug(f"ä¼‘çœ  {sleep_time} ç§’")
            time.sleep(sleep_time)
            
        except Exception as e:
            logger.error(f"æ›´æ–°å¾ªç¯å‡ºé”™: {str(e)}")
            time.sleep(300)  # å‡ºé”™åç­‰å¾…5åˆ†é’Ÿå†é‡è¯•

if __name__ == "__main__":
    main()